{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method #1. Tree-based classification\n",
    "\n",
    "#Step 1: Collecting the data\n",
    "import pandas as pd # import the csv file \n",
    "input_file = \"C:/MyData Late-Spring/530 Machine Learning/data/credit.csv\" \n",
    "credit = pd.read_csv(input_file)\n",
    "#If you want to see how the dataset is organized, you may use command head() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Income</th>\n",
       "      <th>Limit</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Cards</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Student</th>\n",
       "      <th>Married</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.891</td>\n",
       "      <td>3606</td>\n",
       "      <td>283</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>11</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>106.025</td>\n",
       "      <td>6645</td>\n",
       "      <td>483</td>\n",
       "      <td>3</td>\n",
       "      <td>82</td>\n",
       "      <td>15</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Asian</td>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>104.593</td>\n",
       "      <td>7075</td>\n",
       "      <td>514</td>\n",
       "      <td>4</td>\n",
       "      <td>71</td>\n",
       "      <td>11</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Asian</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>148.924</td>\n",
       "      <td>9504</td>\n",
       "      <td>681</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>11</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Asian</td>\n",
       "      <td>964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID   Income  Limit  Rating  Cards  Age  Education  Gender Student Married  \\\n",
       "0   1   14.891   3606     283      2   34         11    Male      No     Yes   \n",
       "1   2  106.025   6645     483      3   82         15  Female     Yes     Yes   \n",
       "2   3  104.593   7075     514      4   71         11    Male      No      No   \n",
       "3   4  148.924   9504     681      3   36         11  Female      No      No   \n",
       "\n",
       "   Ethnicity  Balance  \n",
       "0  Caucasian      333  \n",
       "1      Asian      903  \n",
       "2      Asian      580  \n",
       "3      Asian      964  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Income</th>\n",
       "      <th>Limit</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Cards</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>200.500000</td>\n",
       "      <td>45.218885</td>\n",
       "      <td>4735.600000</td>\n",
       "      <td>354.940000</td>\n",
       "      <td>2.957500</td>\n",
       "      <td>55.667500</td>\n",
       "      <td>13.450000</td>\n",
       "      <td>520.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>115.614301</td>\n",
       "      <td>35.244273</td>\n",
       "      <td>2308.198848</td>\n",
       "      <td>154.724143</td>\n",
       "      <td>1.371275</td>\n",
       "      <td>17.249807</td>\n",
       "      <td>3.125207</td>\n",
       "      <td>459.758877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.354000</td>\n",
       "      <td>855.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100.750000</td>\n",
       "      <td>21.007250</td>\n",
       "      <td>3088.000000</td>\n",
       "      <td>247.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>41.750000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>68.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>200.500000</td>\n",
       "      <td>33.115500</td>\n",
       "      <td>4622.500000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>459.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>300.250000</td>\n",
       "      <td>57.470750</td>\n",
       "      <td>5872.750000</td>\n",
       "      <td>437.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>863.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>186.634000</td>\n",
       "      <td>13913.000000</td>\n",
       "      <td>982.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID      Income         Limit      Rating       Cards  \\\n",
       "count  400.000000  400.000000    400.000000  400.000000  400.000000   \n",
       "mean   200.500000   45.218885   4735.600000  354.940000    2.957500   \n",
       "std    115.614301   35.244273   2308.198848  154.724143    1.371275   \n",
       "min      1.000000   10.354000    855.000000   93.000000    1.000000   \n",
       "25%    100.750000   21.007250   3088.000000  247.250000    2.000000   \n",
       "50%    200.500000   33.115500   4622.500000  344.000000    3.000000   \n",
       "75%    300.250000   57.470750   5872.750000  437.250000    4.000000   \n",
       "max    400.000000  186.634000  13913.000000  982.000000    9.000000   \n",
       "\n",
       "              Age   Education      Balance  \n",
       "count  400.000000  400.000000   400.000000  \n",
       "mean    55.667500   13.450000   520.015000  \n",
       "std     17.249807    3.125207   459.758877  \n",
       "min     23.000000    5.000000     0.000000  \n",
       "25%     41.750000   11.000000    68.750000  \n",
       "50%     56.000000   14.000000   459.500000  \n",
       "75%     70.000000   16.000000   863.000000  \n",
       "max     98.000000   20.000000  1999.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the describe() command to check what is in the credit object created to hold the data in Python.\n",
    "#The describe command is shown below with the first few lines returned. \n",
    "credit.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 12 columns):\n",
      "ID           400 non-null int64\n",
      "Income       400 non-null float64\n",
      "Limit        400 non-null int64\n",
      "Rating       400 non-null int64\n",
      "Cards        400 non-null int64\n",
      "Age          400 non-null int64\n",
      "Education    400 non-null int64\n",
      "Gender       400 non-null object\n",
      "Student      400 non-null object\n",
      "Married      400 non-null object\n",
      "Ethnicity    400 non-null object\n",
      "Balance      400 non-null int64\n",
      "dtypes: float64(1), int64(7), object(4)\n",
      "memory usage: 37.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#Step 2:Exploring the data\n",
    "#There are many ways you can further check the data in this object, e.g. info or describe.\n",
    "#For example, you can use the info() command to get information about properties of all the variables \n",
    "credit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Creditability'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3077\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3078\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Creditability'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-13bdfcbc20c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#What is target variable? Let’s store it in a new variable.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcredit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Creditability'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2688\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2693\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2695\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2697\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2489\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4115\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3078\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Creditability'"
     ]
    }
   ],
   "source": [
    "#What is target variable? Let’s store it in a new variable. \n",
    "target = credit['Creditability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you want to see the number of each category of target variable you can use following command: \n",
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In order to develop the tree-based classification model you need to split the data into training and test records. \n",
    "#There are many ways that we can make this split. \n",
    "#We introduce two methods here:\n",
    "\n",
    "#Method 1: # Generate random numbers \n",
    "import random \n",
    "random.seed(12345) \n",
    "indx = random.sample(range(0, 1000), 1000) \n",
    "credit_rand = credit.iloc[indx] \n",
    "target_rand = target.iloc[indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can see the result of randomization using:\n",
    "credit_rand.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure that randomizing your data has not made any substantive changes to it, i.e. the means should still be the same\n",
    "credit_rand.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare this result to what we had earlier.\n",
    "#You’ll need to subset the observations (records) to establish the training set and the test set. \n",
    "#Sort of a rule of thumb is to use between 75% and 90% of the records for the training set. \n",
    "#There are many ways to do this in Python. For example, you can use: \n",
    "credit_train = credit_rand.iloc[0:700] \n",
    "credit_test = credit_rand.iloc[700:1000] \n",
    "target_train = target_rand.iloc[0:700] \n",
    "target_test = target_rand.iloc[700:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If the randomization went well then the percentages between splits should be close.\n",
    "#Before we checked on the number of defaults for both training and test.This time we want to see the percentage of each: \n",
    "target_train.value_counts()/700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_test.value_counts()/300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2 of splitting the model \n",
    "from sklearn.model_selection import train_test_split \n",
    "y = target \n",
    "X = credit.drop(['Creditability'],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Training a model on the data\n",
    "#You only need one command line to create the decision tree model. \n",
    "#However, now you need to set-up this command so that the algorithm knows that the class or \n",
    "#response variable is in the 17th column. The command and the model created are: \n",
    "\n",
    "# Design decision tree \n",
    "from sklearn import tree \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "model = tree.DecisionTreeClassifier() \n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To visualize the model, we can use:                                    \n",
    "from IPython.display import SVG \n",
    "from graphviz import Source \n",
    "from IPython.display import display \n",
    "graph = Source(tree.export_graphviz(model, out_file=None , feature_names=X.columns, class_names=['default', 'no default'] , filled = True)) \n",
    "display(SVG(graph.pipe(format='svg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Evaluating Model Performance\n",
    "#We still need to use our test set to evaluate/validate the model’s overall performance. \n",
    "#To do this we’ll use the predict() command as follows:\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_predict = model.predict(X_test) \n",
    "print(confusion_matrix(y_test, y_predict)) \n",
    "print(accuracy_score(y_test, y_predict)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################################\n",
    "# Q1- If you see the accuracy 0f 100%, what does it mean? Does this mean that we design a perfect model? \n",
    "#     This is some thing that needs more discussion. Write a few sentences about accuracy of 100%.\n",
    "# Answer 1- If we see the see the accuracy 0f 100% then this situation is called Overfit when model having a accuracy  \n",
    "# more than 95%.Overfitting is a modeling error which occurs when a function is too closely fit to a limited set of data \n",
    "# points.I experienced the same thing that certain algorithms like trees are prone to overfitting, due to their \n",
    "# tuning parameters.\n",
    "###########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2-Random forest.Let’s use the same dataset but this time for random forest. \n",
    "#Use the similar strategy described in course to see the accuracy.\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=52)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_predict))\n",
    "print(accuracy_score(y_test,y_predict)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One of the interesting properties of Random forest algorithm is that it lets you see the importance of features.\n",
    "import pandas as pd \n",
    "feature_importances = pd.DataFrame(clf.feature_importances_,index = X_train.columns,\n",
    "columns=['importance']).sort_values('importance',ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################################\n",
    "# Q2 –What are the three most important features in this model.\n",
    "# Answer 2- Credit Amount  \t0.139151\n",
    "#          Account Balance \t0.108843\n",
    "#          Age (years) \t0.106622\n",
    "# Change the random seed to 23458 and find the new accuracy of random forest.\n",
    "# Answer - the accuracy increased from 68.0 to 73.0 , it means the random forest helped improved the model.\n",
    "###########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=23458)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "y_predict = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test,y_predict))\n",
    "print(accuracy_score(y_test,y_predict)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method #2. Random forest\n",
    "#Let’s use the same dataset but this time for random forest. Use the similar strategy described in course to see the accuracy. # Part 2 Random forest \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.30,random_state=23458)\n",
    "clf = RandomForestClassifier() \n",
    "clf.fit(X_train, y_train)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(X_test) \n",
    "print(confusion_matrix(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, y_predict)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method #3. Adding regression to trees\n",
    "#Step 1: Collecting the Data\n",
    "input_file = \"C:/MyData Late-Spring/530 Machine Learning/data/whitewines.csv\" \n",
    "wine = pd.read_csv(input_file) \n",
    "wine.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will use regression we should check to see if the class variable, quality, follows a normal distribution or \n",
    "#is nearly normal. # Plot the target variable \n",
    "import matplotlib.pyplot as plt \n",
    "# An \"interface\" to matplotlib.axes.Axes.hist() method \n",
    "n, bins, patches = plt.hist(x=wine['quality'], bins='auto', color='b', ) \n",
    "plt.xlabel('Quallity Value') \n",
    "plt.ylabel('Frequency') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Exploring and Preparing the Data\n",
    "#Essentially all we need to do this time is to subset our data into training and test sets. \n",
    "#Let’s use an approximately 60% for training and 40% for testing split of the observations.\n",
    "\n",
    "#Step 3: Training a Model on the Data Design the model similar the way you did earlier. \n",
    "target = wine['quality']\n",
    "target.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2 of splitting the model \n",
    "from sklearn.model_selection import train_test_split \n",
    "y = target \n",
    "X = wine.drop(['quality'],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=1234)\n",
    "model = tree.DecisionTreeClassifier() \n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get the basic information about the tree, you can export the information of the model to a .dot file. \n",
    "from sklearn.tree import export_graphviz \n",
    "# export the decision tree to a tree.dot file \n",
    "# for visualizing the plot easily anywhere \n",
    "export_graphviz(model, out_file ='tree.dot', feature_names =X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#You may see the regression graph using following commands: \n",
    "from graphviz import Source \n",
    "dot_data = tree.export_graphviz(model, out_file=None,feature_names=X.columns, filled=True, rounded=True, special_characters=True) \n",
    "graph = Source(dot_data) \n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_predict = model.predict(X_test) \n",
    "print(confusion_matrix(y_test, y_predict)) \n",
    "print(accuracy_score(y_test, y_predict)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Evaluating Model Performance\n",
    "import numpy as np\n",
    "np.corrcoef(y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import math \n",
    "\n",
    "\n",
    "rmse= math.sqrt(mean_squared_error(y_test, y_predict))\n",
    "print(rmse)\n",
    "\n",
    "RMSE =mean_squared_error(y_predict,y_test)**0.5\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our model has a error rate of 0.84.\n",
    "###########################################################################################################################\n",
    "# Q3- What is your interpretation about this amount of RMSE?\n",
    "# Answer 3- As to 0.84 is very likely to indicate overfitting.Lower the RMSE it indicates the better fit , in this case it \n",
    "# is very high indicating overfitting.\n",
    "###########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method #4. News Popularity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset\n",
    "input_file = \"C:/MyData Late-Spring/530 Machine Learning/data/OnlineNewsPopularity_for_python.csv\" \n",
    "df = pd.read_csv(input_file, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs): pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X = df[0:58]\n",
    "Y = df['shares']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the statistics of original target attribute\n",
    "data = df[df.keys()[-1]]\n",
    "data.describe()\n",
    "# Encode the label by threshold 1400\n",
    "from sklearn import preprocessing\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "popular_label = pd.Series(label_encoder.fit_transform(data>=1400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular = df.shares >= 1400\n",
    "unpopular = df.shares < 1400\n",
    "df.loc[popular,'shares'] = 1\n",
    "df.loc[unpopular,'shares'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=list(df.columns[2:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset to 70-30 training and testing resp.\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[features], df['shares'], test_size=0.30 ,random_state=23458)\n",
    "\n",
    "#Shape of  training and test datasets\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design decision tree \n",
    "from sklearn import tree \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "model = tree.DecisionTreeClassifier() \n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree model and accuracy\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_predict = model.predict(X_test) \n",
    "print(confusion_matrix(y_test, y_predict)) \n",
    "print(accuracy_score(y_test, y_predict)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE =mean_squared_error(y_predict,y_test)**0.5\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random forest\n",
    "#Let’s use the same dataset but this time for random forest. Use the similar strategy described in course to see the accuracy. # Part 2 Random forest \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "clf = RandomForestClassifier() \n",
    "clf.fit(X_train, y_train)\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_predict)) \n",
    "print(accuracy_score(y_test, y_predict)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging for Visual Comparison\n",
    "log_cols=[\"Classifier\", \"Accuracy\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__  \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    train_predictions = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, train_predictions)\n",
    "    print(\"Accuracy: {:.4%}\".format(acc))\n",
    "\n",
    " \n",
    "    \n",
    "print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One of the interesting properties of Random forest algorithm is that it lets you see the importance of features.\n",
    "import pandas as pd \n",
    "feature_importances = pd.DataFrame(clf.feature_importances_,index = X_train.columns,\n",
    "columns=['importance']).sort_values('importance',ascending=False)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE =mean_squared_error(y_predict,y_test)**0.5\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change random seed to 23458 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################################\n",
    "# Q4 - Try decision tree and random forest and evaluate the model\n",
    "# Answer 4- Random forest model seems to work better than decision tree \n",
    "# Accuracy for Decision tree is 58.4665%\n",
    "# Accuracy for Random forest tree is 62.4264%\n",
    "# RMSE  for Decision tree is 0.64\n",
    "# RMSE for Random forest tree is 0.61\n",
    "# 3 important features identified are:\n",
    "# kw_avg_avg \t0.044775\n",
    "# kw_max_avg \t0.039475\n",
    "# LDA_02 \t0.034346\n",
    "##########################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
